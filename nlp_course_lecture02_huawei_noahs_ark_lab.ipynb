{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0FH7ZDCHbSM"
      },
      "source": [
        "## Seminar 2\n",
        "\n",
        "### Intro to PyTorch\n",
        "\n",
        "based on official [PyTorch Blitz Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRCnX657HbSU"
      },
      "source": [
        "## To install PyTorch please follow instructions from official [website](https://pytorch.org/get-started/locally/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaFLTcQAHbSV"
      },
      "source": [
        "### What is PyTorch?\n",
        "\n",
        "* It's a package for scientific computations, basically, a replacement for NumPy, that supports GPUs.\n",
        "* It's a deep learning research platform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRx-3BmvHbSW"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are similar to NumPy's ndarrays, with the exception of being able to be operated with using GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "3EpI8IEdHbSX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efjPGo2hHbSd"
      },
      "source": [
        "To construct a randomly initialized matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mfaLeKTHbSe",
        "outputId": "ad6e570a-c1ca-4b84-c175-3ac88f83ffbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6372, 0.1697, 0.4210],\n",
            "        [0.0900, 0.1915, 0.7062],\n",
            "        [0.4440, 0.2796, 0.2975],\n",
            "        [0.9916, 0.2178, 0.3695],\n",
            "        [0.7804, 0.1118, 0.3410]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCS32yP5HbSf"
      },
      "source": [
        "To construct a matrix, filled with zeros and data-type long:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV0vu4fWHbSf",
        "outputId": "e0f5edc4-3735-49b2-9834-4fff4ae7ab5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR5_fxQjHbSg"
      },
      "source": [
        "A tensor may be initialized directly from data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XaCGIsrHbSg",
        "outputId": "9312c873-4681-4b63-eb0d-0a4c698522d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enXt3O2EHbSh"
      },
      "source": [
        "A tensor may be created using an existing tensor. The new one will inherit all the properties of the one, that was passed as a parameter, apart from those, that were parametrized explicitly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfYa2XNtHbSh",
        "outputId": "45ef116b-b817-4a3e-970e-a9f48f53c02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[-0.6322, -0.9671, -0.1247],\n",
            "        [ 2.0053,  0.4415,  2.3298],\n",
            "        [ 1.4352,  0.5937, -1.1980],\n",
            "        [ 0.5494, -0.4754, -0.2074],\n",
            "        [ 0.1042,  1.0216, -1.3735]])\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(5, 3)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNENKpeeHbSi"
      },
      "source": [
        "To check the size of a tensor we use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbKtu1IjHbSi",
        "outputId": "8af8b51c-99c6-4bbf-a80c-2399a2b4e2a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "x.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way:"
      ],
      "metadata": {
        "id": "5AOJrJ29MuY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_amAGT3oMrwy",
        "outputId": "326b2247-4e28-4f9f-e166-de5d4e180217"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjZS-Ga0HbSi"
      },
      "source": [
        "NB! The type torch.Size is an abstraction from a mere tuple, so it supports all the tuple operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1WW3Ev7HbSj"
      },
      "source": [
        "### Operations\n",
        "\n",
        "PyTorch is so pythonic, that it implements operations on tensors in many different syntaxes to match everyones needs and tastes. Let us take a look at the addition operation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zpTGOKSHbSj",
        "outputId": "b44a4538-21ba-45ee-d69a-63beb34c6496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6134, -0.8136,  0.6153],\n",
            "        [ 2.7688,  0.4961,  3.0683],\n",
            "        [ 1.8372,  1.2829, -0.8196],\n",
            "        [ 1.2146,  0.5219,  0.5046],\n",
            "        [ 1.0140,  1.4486, -0.6107]])\n"
          ]
        }
      ],
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDC_fsaAHbSk",
        "outputId": "6b74df23-f15a-4c03-b0ad-01f517d25489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6134, -0.8136,  0.6153],\n",
            "        [ 2.7688,  0.4961,  3.0683],\n",
            "        [ 1.8372,  1.2829, -0.8196],\n",
            "        [ 1.2146,  0.5219,  0.5046],\n",
            "        [ 1.0140,  1.4486, -0.6107]])\n"
          ]
        }
      ],
      "source": [
        "print(torch.add(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcWj30xGHbSl"
      },
      "source": [
        "In case you need it, you can pass an out variable as a parameter to any operation like add:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcAlCBb-HbSl",
        "outputId": "1bf0bf8f-370b-43d8-f90d-f5e472c17643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6134, -0.8136,  0.6153],\n",
            "        [ 2.7688,  0.4961,  3.0683],\n",
            "        [ 1.8372,  1.2829, -0.8196],\n",
            "        [ 1.2146,  0.5219,  0.5046],\n",
            "        [ 1.0140,  1.4486, -0.6107]])\n"
          ]
        }
      ],
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieKpBbxCHbSm"
      },
      "source": [
        "Tensor objects support all the operations as methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXRpa24sHbSm",
        "outputId": "d85f3865-ed0f-4e0b-abf8-9e88f58ca402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6134, -0.8136,  0.6153],\n",
              "        [ 2.7688,  0.4961,  3.0683],\n",
              "        [ 1.8372,  1.2829, -0.8196],\n",
              "        [ 1.2146,  0.5219,  0.5046],\n",
              "        [ 1.0140,  1.4486, -0.6107]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "x.add(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQNzjG-HbSm"
      },
      "source": [
        "In case you need to perform an operation in-place, you use the operation_ syntax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrZ1ScyaHbSn",
        "outputId": "24d4f872-f064-4deb-d21e-32a67b3a8a9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6134, -0.8136,  0.6153],\n",
              "        [ 2.7688,  0.4961,  3.0683],\n",
              "        [ 1.8372,  1.2829, -0.8196],\n",
              "        [ 1.2146,  0.5219,  0.5046],\n",
              "        [ 1.0140,  1.4486, -0.6107]])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "x.add_(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlgALC8xHbSn"
      },
      "source": [
        "The result of an in-place operation is stored in the left operand object, in this particular case in x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwdsECG9HbSn",
        "outputId": "820cf2ec-404a-426e-e0f2-988839827659"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6134, -0.8136,  0.6153],\n",
              "        [ 2.7688,  0.4961,  3.0683],\n",
              "        [ 1.8372,  1.2829, -0.8196],\n",
              "        [ 1.2146,  0.5219,  0.5046],\n",
              "        [ 1.0140,  1.4486, -0.6107]])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7Lj2P0UHbSo"
      },
      "source": [
        "The sugarish NumPy indexing syntax is also supported:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE5Fah0iHbSo",
        "outputId": "7d557da1-1ee2-4aa5-dd4a-e2e514f94fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.8136,  0.4961,  1.2829,  0.5219,  1.4486])\n"
          ]
        }
      ],
      "source": [
        "print(x[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvS7Y3YgHbSo"
      },
      "source": [
        "In case there is a need to resize (*reshape*) a tensor, the ``` view ``` method comes into action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZF0GUhtHbSo",
        "outputId": "98a3b1fc-8546-45e7-ae9f-81ff3c99c417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 denotes the original dimension size\n",
        "print(x.size(), y.size(), z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz551EmlHbSp"
      },
      "source": [
        "To get the number out of the tensor use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsAk9MudHbSp",
        "outputId": "85b2ca9a-7549-4544-e46d-3173d35f55f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1627])\n",
            "-0.16270415484905243\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fY57dMyHbSp",
        "outputId": "e462b4cf-7a5c-4ca0-9c3c-1e16ff8a36e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.1159268617630005"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "y[1].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPqMWMNoHbSq"
      },
      "source": [
        "In case we need to check, if CUDA is available, we use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "gh929KmCHbSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "908c88c1-15ba-4974-9368-eef47692adda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8373], device='cuda:0')\n",
            "tensor([0.8373], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NSTCyMhHbSq"
      },
      "source": [
        "### Autograd\n",
        "\n",
        "The next thing that is worth looking at is the automatic gradient computation module of pyTorch. It is called\n",
        "*torch.autograd* . This module does all the *magic* that is connected with gradient computations, using a sofisticated computation graph architecture, that is going to be covered later. For now we will get to know only basic concepts of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkXNqksnHbSr"
      },
      "source": [
        "To include a `Tensor` into the computation graph, its `.requires_grad` attribute should be set to `True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcdJCnP5HbSr",
        "outputId": "0ec119d2-13ad-4e9d-ce22-cd57356203b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0VM8aIlHbSr"
      },
      "source": [
        "After any operation is applied (in this particular case - addition), a `Function` object is assigned to the `.grad_fn` attribute of the tensor `y` and added to the computation graph for backward propagation of the gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcFl4AWHbSs",
        "outputId": "6a783a90-b021-4e9a-831c-77d4cfa99c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0Wp4GjNHbSs",
        "outputId": "867cda3e-2fdc-43ad-8ad2-174364518817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7f4d6aef3640>\n"
          ]
        }
      ],
      "source": [
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of4Eh18aHbSs",
        "outputId": "27309e48-d915-46f5-93a1-7e6e9fea0ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39gLEvmAHbSt"
      },
      "source": [
        "This `.grad_fn` attribute can be changed on the fly. See the difference: if a tensor does not require gradient, it is not included into the computation graph, hence it does not store any backward function. However, once `.grad_fn` changed to `True`, all the operations start to be tracked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va5zd2xMHbSt",
        "outputId": "5a1f0639-6b17-4727-ad27-26eee89fb648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f4d621ee190>\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZcXFmziHbSt"
      },
      "source": [
        "One of the most important things in the torch framework is the `.backward()` method. It triggers the calculation of the gradients for all the nodes (e.g. neural net parameters) in the computation graph that are chained to the callee node. \n",
        "\n",
        "NB! `.backward()` when called on a \\[1, 1\\] tensor, requires no arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "yyNpdWrzHbSu"
      },
      "outputs": [],
      "source": [
        "out.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSpM1ECkHbSu",
        "outputId": "6257a7f5-9815-4d11-8d93-4a9ad9af7a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeBKDVmzHbSv",
        "outputId": "a431410b-4df5-401c-ae03-03d80788f6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1226.9231,   916.6340,   181.5013], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD3WUBM3HbSw"
      },
      "source": [
        "If there is a need to stop autograd from tracking history on Tensors you can use either context manager:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueu6nMZQHbSw",
        "outputId": "dac034f6-7764-49d9-ef8e-b3b32c44eaab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUPp-OS8HbSw"
      },
      "source": [
        "or `.detach()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3xMiiHvHbSx",
        "outputId": "6df70f4d-bcd4-45da-e2c6-beca80c08b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9fIoqlRHbSx"
      },
      "source": [
        "## Logistic Regression Using PyTorch\n",
        "### based on [this](https://blog.goodaudience.com/awesome-introduction-to-logistic-regression-in-pytorch-d13883ceaa90) blogpost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LatTrcvzHbSy"
      },
      "source": [
        "Basically, most of pyTorch modeling can be broken down into these steps:\n",
        "* loading the dataset\n",
        "* making the dataset iterable\n",
        "* instantiating the **model** class\n",
        "* instantiating the **loss** class\n",
        "* instantiating the **optimizer** class\n",
        "* training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azvJ-OFGHbSy"
      },
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COb91GeBHbSy",
        "outputId": "3ae3dbb3-a5b9-44f2-ed8b-d8f5271bef08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.8/dist-packages (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext) (2.25.1)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchtext) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchtext) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "Uj7jQablHbSz"
      },
      "outputs": [],
      "source": [
        "from torchtext import data\n",
        "from torch.nn import functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "bJQnbej3HbSz"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "scrolled": true,
        "id": "EbWLu_OaHbSz"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "eAn6H6lkHbSz"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSZgyG66HbS0",
        "outputId": "c9113885-f0eb-4bbb-8eac-eb05554c43c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "nltk.download(\"movie_reviews\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "8XidgYqZHbS0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "fDjiBAmsHbS0"
      },
      "outputs": [],
      "source": [
        "POS = \"pos\"\n",
        "NEG = \"neg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "fsPD7gp3HbS0"
      },
      "outputs": [],
      "source": [
        "text_sentiments = (POS, NEG)\n",
        "\n",
        "train_data_list = []\n",
        "test_data_list = []\n",
        "\n",
        "examples = []\n",
        "\n",
        "for sentiment in text_sentiments:\n",
        "    for filename in os.listdir(os.path.join(nltk.corpus.movie_reviews.root.path, sentiment)):\n",
        "        with open(os.path.join(nltk.corpus.movie_reviews.root.path, sentiment, filename), \"r\", encoding=\"utf-8\") as file:\n",
        "            examples.append({\"text\": file.read().strip(),\n",
        "                             \"sentiment\": int(sentiment == POS)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ2BilN2HbS1",
        "outputId": "32fa2fdc-1b29-44aa-f57b-624f77ea5456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "gJmBM_OmHbS1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "el_AOOPpHbS2"
      },
      "outputs": [],
      "source": [
        "examples_df = pd.DataFrame(examples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cNkyFZLtKFnB",
        "outputId": "2eaa62ba-dba1-4f4a-bf16-172cd865a331"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  sentiment\n",
              "0  first , i am not a big fan of the x-files tv s...          1\n",
              "1  the thought-provoking question of tradition ov...          1\n",
              "2  the small-scale film , in limited release , \" ...          1\n",
              "3  metro i've seen san francisco in movies many t...          1\n",
              "4  three things i learned from \" being john malko...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-493d2f6d-f23f-462d-9aa0-d8e4046b6e3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first , i am not a big fan of the x-files tv s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the thought-provoking question of tradition ov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the small-scale film , in limited release , \" ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>metro i've seen san francisco in movies many t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>three things i learned from \" being john malko...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-493d2f6d-f23f-462d-9aa0-d8e4046b6e3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-493d2f6d-f23f-462d-9aa0-d8e4046b6e3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-493d2f6d-f23f-462d-9aa0-d8e4046b6e3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "vxh9T2RYHbS2"
      },
      "outputs": [],
      "source": [
        "examples_df = examples_df.sample(frac=1)\n",
        "train_df = examples_df.sample(frac=0.7)\n",
        "test_df = examples_df.drop(index=train_df.index)\n",
        "train_texts, train_labels = train_df.text.values, train_df.sentiment.values\n",
        "test_texts, test_labels = test_df.text.values, test_df.sentiment.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I-fiAboHbS2",
        "outputId": "6b95e5b1-a26c-4d70-dee0-6e422c6ed8e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFDFos7XHbS3",
        "outputId": "c0640d1c-7c2e-4882-8512-2ac331c9b555"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 600, 600)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "source": [
        "len(test_df.text.values), len(test_df.sentiment.values), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "_s4vOGQTHbS3"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any, Iterable\n",
        "from collections import Counter, OrderedDict\n",
        "import math\n",
        "from itertools import islice\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "JRpjJXIdHbS3"
      },
      "outputs": [],
      "source": [
        "class TfIdfVectorizer:\n",
        "\n",
        "            \n",
        "    def __init__(self, lower=True, tokenizer_pattern=r\"(?i)\\b[a-z]{2,}\\b\"):  # ?i for case insensitive match\n",
        "        # What are the drawbacks of this tokenization?\n",
        "        self.lower = lower  \n",
        "        self.tokenizer_pattern = re.compile(tokenizer_pattern)\n",
        "        self.vocab_df = OrderedDict()\n",
        "        \n",
        "    def __tokenize(self, text: str) -> List[str]:\n",
        "        return self.tokenizer_pattern.findall(text.lower() if self.lower else text)\n",
        "    \n",
        "    def fit(self, texts: Iterable[str]):\n",
        "        term_id = 0\n",
        "        for doc_idx, doc in enumerate(texts):\n",
        "            tokenized = self.__tokenize(doc)\n",
        "            for term in tokenized:\n",
        "                if term not in self.vocab_df:\n",
        "                    self.vocab_df[term] = {}  # Creating term-based dict\n",
        "                    self.vocab_df[term][\"doc_ids\"] = {doc_idx}  # For each term adding documents where it is found\n",
        "                    self.vocab_df[term][\"doc_count\"] = 1  # Initialising doc count\n",
        "                    self.vocab_df[term][\"id\"] = term_id  # Adding term id in our vector\n",
        "                    term_id += 1\n",
        "                elif doc_idx not in self.vocab_df[term][\"doc_ids\"]:\n",
        "                    self.vocab_df[term][\"doc_ids\"].add(doc_idx)  # Adding new documents for existing terms\n",
        "                    self.vocab_df[term][\"doc_count\"] += 1  # Incrementing count\n",
        "        texts_len = len(texts)  # Number of texts\n",
        "        for term in self.vocab_df:\n",
        "            # Calculating idf\n",
        "            self.vocab_df[term][\"idf\"] = math.log(texts_len / self.vocab_df[term][\"doc_count\"])\n",
        "        \n",
        "        \n",
        "    def transform(self, texts: Iterable[str]) -> torch.sparse.LongTensor:\n",
        "        values = []\n",
        "        doc_indices = []\n",
        "        term_indices = []\n",
        "        for doc_idx, raw_doc in enumerate(texts):\n",
        "            term_counter = {}\n",
        "            for token in self.__tokenize(raw_doc):\n",
        "                if token in self.vocab_df:\n",
        "                    term = self.vocab_df[token]\n",
        "                    term_idx = term[\"id\"]\n",
        "                    term_idf = term[\"idf\"]\n",
        "                    if term_idx not in term_counter:\n",
        "                        term_counter[term_idx] = term_idf\n",
        "                    else:\n",
        "                        term_counter[term_idx] += term_idf\n",
        "            term_indices.extend(term_counter.keys())\n",
        "            values.extend(term_counter.values())\n",
        "            doc_indices.extend([doc_idx] * len(term_counter))\n",
        "        # Transferring dict and encoded texts to cuda\n",
        "        indices = torch.LongTensor([doc_indices, term_indices]).to(DEVICE)\n",
        "        values_tensor = torch.LongTensor(values).to(DEVICE)\n",
        "        # To optimise calculations we make it sparse\n",
        "        tf_idf = torch.sparse.LongTensor(indices, values_tensor, torch.Size([len(texts), len(self.vocab_df)])).to(DEVICE)\n",
        "        return tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snQFHxK9HbS4",
        "outputId": "285c2496-92a3-4c2d-a5fe-0fa821af773c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.55 s, sys: 33.2 ms, total: 1.58 s\n",
            "Wall time: 1.75 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "vectorizer = TfIdfVectorizer()\n",
        "vectorizer.fit(train_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHDtWJS_HbS4",
        "outputId": "e968fe20-beaf-4cbe-c252-df94dcfd284d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-169-f27bf72b0254>:53: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  values_tensor = torch.LongTensor(values).to(DEVICE)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.84 s, sys: 20.4 ms, total: 1.86 s\n",
            "Wall time: 1.88 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train_data = vectorizer.transform(train_texts)\n",
        "test_data = vectorizer.transform(test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "apBAR7cTJrsO",
        "outputId": "572565e1-402c-4cae-e457-7b11c1436f05"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"in 1912 , a ship set sail on her maiden voyage across the atlantic for america . \\nthis ship was built to be the largest ship in the world , and she was . \\nshe was also build to be one of the most luxurious , and that she was . \\nfinally , she was built to be unsinkable and that unfortunately she was not . \\nto get a ticket for this voyage you either : spent a life's savings to get to america to start life anew , were part of the upper class and had the money to spare , or finally were lucky enough to have a full house in a poker match by the docks like jack dawson . \\njack dawson makes the trip , and happens to be at the right place at the right time . \\nrose dewitt bukater , a first class passenger , climbs the railings at the aft of the ship with thoughts of jumping . \\nthus is started a tale of romance and intrigue , and a tale of death and tragedy . . . \\nthis movie is about a tragic event that took place a great many years ago , an even that should not be taken lightly as any other bit of historical trivia . \\nthe movie titanic shows what happened , maybe not with a 100% degree of accuracy , but it still shows it very realisticaly . \\nnow the titanic is both a story on its own and a backdrop for a story . \\nit serves as both admirably , brining forth an interesting story that although simple in its most simple premise is very captivating . \\nthis movie is very emotional simply because of what it is , but that alone is not enough . \\nthe story is brought out with a certain style that makes is so much more emotional and so much more effective . \\nmovies such as this will not be forgotten all too quickly and unfortunately then are not something that is produced by hollywood with any great frequency . \\nthe attention to detail that was paid is remarkable . \\nthe whole premise for the telling of the story is interesting , with the showing of brand new footage from the wreck of the titanic adding much flavor to an already good movie . \\npart of the magical chemistry behind this story is the acting , and for this movie its extremely good acting from the whole cast . \\nthe performances put in by the main stars is something to be admired . \\nthe characters were played out so memorably that both leonardo dicaprip and kate winslet should receive at the least nominations for their roles . \\nlooking at the acting done in the movie it seems as if they aren't acting but are actually the characters in the movie . \\nthe casting for the movie could really have been better , in my humble opinion that is . \\none character that will most likely not be mentioned by any other review or commentary about this film is that of the ship itself . \\nyes , you read correctly , the ship is a character . \\nhow is the titanic a character ? \\nyou ask well simple , a ship had a certain character about it and as most sailors and boats men will tell you . \\nthis character is everything about the ship from its specifications to its luxuries and the titanic was no stranger to this . \\nmr . cameron brings the ship to life in an almost literal sense . \\nall this adds to the movie in a certain way that most hollywood productions cant seem to grasp . \\nnow , to produce the effect that i mentioned above and to sink the ship itself are feats that are accomplished by special effects wizards . \\nthe effects in this movie range from marvelous costumes to beautifully rendered scenes of the ships sinking . \\nin some respects you cannot tell that the effects are there , you simply think that what you see is what happened or what is happening ( if your imagination is good ) . \\nthe technical wizardry done in this movie is just spectacular and actually getting new footage from the wreck of the titanic is unique . \\nthe movie will leave you amazed at the effects , and that is a feat since there is no monsters or aliens in this movie , just humans and an oversized ship . \\nthe movie will amaze you and it will pull on your emotions , the theater that i went to had a few people leaving with tears in their eyes . \\nnow that is not a feat accomplished by most movies , now the fact that the tragedy actually occurred is brought home with something of a punch , i wont spoil the ending and say what happens regardless it is an interesting movie from beginning to the very end . \\nthe historical value of this movie is quite high , and honestly is something that should be watched for the sake of seeing it and seeing the tragedy , for it is extremely well done . \\nthe method of telling the story is also good , maybe not totally unique but effective none the less . \\nregardless of anything mentioned above this movie is a grandiose production and the sheer size of the project undertaken is something to be marveled at . \\nthe simple fact that the movie is smashingly successful at what it aims to achieve is just astonishing . \\nif you get the chance to see this movie go ! ! ! \\nit might not be the best movie in the world . . \\nbut it ranks fairly highly and is well worth the time spent watching it . \\nduring none of the 3 hours and 13 minutes of the movie are you bored nor does your attention wane from the movie .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWA827zEMlDJ",
        "outputId": "61933384-a653-4c37-c97f-8dbf9f513c26"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(indices=tensor([[ 23, 395, 396, 397, 241, 246, 398, 399, 321,  20, 400,\n",
              "                        149, 401,  97,  93, 402,  40,  52, 403, 109,  14, 404,\n",
              "                        232, 405,  48,   9, 406, 407,   5, 408, 409, 410,  51,\n",
              "                        135, 411, 105, 210, 412, 413, 414, 415, 416, 322, 417,\n",
              "                        418, 419, 420, 421, 422, 163, 423, 193, 254, 424, 425,\n",
              "                        426, 427, 134, 428, 146, 429, 430, 319, 237, 431, 304,\n",
              "                        432, 372, 389, 433, 434, 435, 371, 436, 437, 438, 439,\n",
              "                          7, 440, 441, 442,   1, 443, 444, 445, 446, 447, 448,\n",
              "                        327, 206, 449, 450, 451, 452, 453, 150, 454,   2, 291,\n",
              "                        332, 455, 456,  90, 207, 160, 457, 458, 459, 460, 461,\n",
              "                        462,  59, 324, 463, 464,  54,  58,  94, 229, 465, 166,\n",
              "                        213,  98, 466, 186, 467, 468, 469, 470, 471, 472, 473,\n",
              "                        474,  92, 475, 476, 477,  55, 478, 479, 102, 480, 481,\n",
              "                        202, 216, 265, 482, 483, 378, 484, 485, 111, 486, 487,\n",
              "                        488,  18, 352, 489, 490, 491, 492, 493, 494, 495, 496,\n",
              "                        497, 498, 499, 500, 353, 121, 501, 502, 503, 323,  68,\n",
              "                        156, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
              "                        201, 275, 514, 515, 516, 517, 518, 519, 520, 521,  44,\n",
              "                        522, 137, 523, 285, 334, 208, 524, 525, 526, 313, 527,\n",
              "                        240, 380, 224, 528, 529, 530, 531, 532, 533, 534, 117,\n",
              "                        101, 535, 536, 537,  57, 538, 200, 539, 540, 541, 542,\n",
              "                        543, 544, 545,  60, 546, 547, 548, 549, 550, 551, 552,\n",
              "                        553, 273, 554, 555, 303, 556, 557, 558, 559, 560, 561,\n",
              "                        562, 563, 564,   0, 565, 566, 567, 568, 569, 293, 570,\n",
              "                        571, 572, 573, 574, 103, 575, 184, 576, 577, 578, 579,\n",
              "                        580, 141, 581, 582, 583, 584, 585, 586, 157, 587, 588,\n",
              "                        589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599,\n",
              "                        600, 601, 602, 603, 604, 605, 606, 607,  50, 608, 609,\n",
              "                        610, 311, 611, 612, 613, 614, 615, 333, 616, 617, 618,\n",
              "                        619, 264, 620, 621, 622, 623, 624, 625, 626, 627, 628,\n",
              "                        629, 630, 631, 632, 633, 326, 634, 635, 636, 637, 638,\n",
              "                        335, 639, 640, 641, 642, 643, 269, 644]]),\n",
              "       values=tensor([ 0, 32,  1,  5,  0,  0,  5,  9,  2,  0,  4,  0,  5,  0,\n",
              "                       2,  6,  0,  1,  5,  2,  0,  3,  1,  3,  0,  0,  3,  5,\n",
              "                       0,  3,  5,  3,  1,  1,  3,  3,  1,  5,  2,  6,  2,  6,\n",
              "                       2,  2,  4,  5,  2,  1,  4,  1,  3,  2,  0,  1,  2,  4,\n",
              "                       3,  0,  6,  0,  5,  9,  2,  2,  4,  1,  2,  2,  0,  3,\n",
              "                       5,  5,  0,  4,  5,  7,  7,  0,  3,  4,  2,  0,  3,  4,\n",
              "                       2,  4,  1, 10,  5,  1,  3,  3,  2,  2,  0,  1,  2,  0,\n",
              "                       0,  3,  2,  4,  0,  2,  1,  1,  7,  4, 22,  3,  2,  5,\n",
              "                       3,  3,  4,  0,  0,  1,  2,  7,  4,  3,  4,  3,  1,  4,\n",
              "                       3,  4,  7,  3,  4,  1,  8,  4,  4,  4,  3,  0,  2,  5,\n",
              "                       0,  7,  1,  0,  1,  0,  4,  1,  0,  3,  3,  0,  0,  2,\n",
              "                       0,  0,  5,  2,  3,  6,  4,  3,  3,  3,  3,  5,  2,  3,\n",
              "                       1,  6,  1,  8,  4,  5,  2,  2,  3,  2,  1,  5,  4,  1,\n",
              "                       1,  1,  1,  1,  4,  1,  1,  5,  4,  7,  3,  4,  4,  1,\n",
              "                       5,  0,  2,  1,  4,  1,  1,  0,  2,  3,  2,  0,  0,  0,\n",
              "                       1,  0,  5,  3,  3,  2,  9,  2,  3,  0,  3,  2,  2,  5,\n",
              "                       0,  2,  1,  5,  4,  1,  3,  1,  6,  7,  1,  3,  2,  3,\n",
              "                       2,  1,  4,  1,  3,  0,  4,  7,  1,  4,  3,  2,  5,  4,\n",
              "                       5,  7,  1,  6,  6,  3,  4,  3,  3,  4,  0,  4,  4,  0,\n",
              "                       4,  2,  0,  1,  1,  3,  3,  3,  3,  5,  1,  3,  1,  5,\n",
              "                       2,  4,  9,  1,  3,  2,  3,  6,  5,  2,  3,  2,  2,  1,\n",
              "                       0,  2,  3,  2,  2,  4,  1,  3,  5,  4,  1,  1,  8,  2,\n",
              "                       0,  3,  1,  1,  3,  3,  3,  3,  4,  2,  4,  1,  1,  5,\n",
              "                       2,  3,  3,  2,  7,  7,  7,  2,  5,  4,  4,  2,  1,  1,\n",
              "                       0,  4,  2,  2,  2,  1,  1,  2,  1,  3,  2,  0,  6]),\n",
              "       device='cuda:0', size=(33804,), nnz=349, layout=torch.sparse_coo)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Y77YSiHbS4"
      },
      "source": [
        "#### Make the dataset iterable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "vq_SGco3HbS4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "zdTFksHaHbS5"
      },
      "outputs": [],
      "source": [
        "train_data_loader = DataLoader(train_texts, batch_size=64)\n",
        "test_data_loader = DataLoader(test_texts, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "tn4T33i6HbS5"
      },
      "outputs": [],
      "source": [
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U2MdUlVHbS5"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "pm9uMecpHbS6"
      },
      "outputs": [],
      "source": [
        "from torch import nn  # nn layers\n",
        "from torch.nn import functional as F  # loss functions\n",
        "\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)  # What is our input dim?\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.softmax(self.linear(x))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "7hLFCLJlHbS6"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegressionModel(len(vectorizer.vocab_df), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "cGTxdy3zHbS6"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "lg95qjQ5HbS7"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ziYNzK0HbS7",
        "outputId": "16a5e86a-04fe-4d07-9725-e6913c7722bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x7f4d110eb5f0>\n",
            "2\n",
            "torch.Size([2, 33804])\n",
            "torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "# Type of parameter object\n",
        "print(model.parameters())\n",
        "\n",
        "# Length of parameters\n",
        "print(len(list(model.parameters())))\n",
        "\n",
        "# FC 1 Parameters\n",
        "print(list(model.parameters())[0].size())\n",
        "\n",
        "# FC 1 Bias Parameters\n",
        "print(list(model.parameters())[1].size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKxJz6W8Xd5l",
        "outputId": "0f60adb6-76e0-4dc0-837c-c4de7f068abf"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionModel(\n",
              "  (linear): Linear(in_features=33804, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "zogMVx-mHbS7"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXq3k_iDHbS8",
        "outputId": "4d780060-ed1f-4ac3-bbf6-8ba7d71ac391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-169-f27bf72b0254>:53: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  values_tensor = torch.LongTensor(values).to(DEVICE)\n",
            "<ipython-input-177-4b9464683140>:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = F.softmax(self.linear(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1\n",
            "Epoch #2\n",
            "Iteration: 50. Loss: 0.6932342648506165. Accuracy: 52.5\n",
            "Epoch #3\n",
            "Epoch #4\n",
            "Iteration: 100. Loss: 0.6932410001754761. Accuracy: 52.66666793823242\n"
          ]
        }
      ],
      "source": [
        "iteration = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch #{epoch}\")\n",
        "    for i, (texts, labels) in enumerate(zip(train_data_loader, batch(train_labels, 64))):\n",
        "        labels = torch.LongTensor(labels).to(DEVICE)\n",
        "        # To take document length into consideration\n",
        "        texts = F.normalize(vectorizer.transform(texts).to(torch.float).to_dense()).requires_grad_()\n",
        "#         print(texts.size(), labels.size(0))\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(texts)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Counting epochs\n",
        "        iteration += 1\n",
        "\n",
        "        if iteration % 50 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for test_texts_batch, test_labels_batch in zip(test_data_loader, batch(test_labels, 64)):\n",
        "                # Load value to a Torch Variable\n",
        "                test_texts_tensor = F.normalize(vectorizer.transform(test_texts_batch).to(torch.float).to_dense())\n",
        "                test_labels_batch = torch.Tensor(test_labels_batch).to(torch.long)\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(test_texts_tensor)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += test_labels_batch.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted.detach().cpu() == test_labels_batch).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iteration, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Using Scikit-learn"
      ],
      "metadata": {
        "id": "_rspoPe-RLmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is more simple way to vectorize documents and train Logistic regression model."
      ],
      "metadata": {
        "id": "sv-qePt9RpUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "3gfhVVpvHbS8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call *fit_transform* to train tfidf vocabulary and vectorize train dataset:"
      ],
      "metadata": {
        "id": "3Gxwv65DSZtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_data = vectorizer.fit_transform(train_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi-4h_r5R0_y",
        "outputId": "e3896420-01f6-498d-dd54-54e28e841f3f"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.08 s, sys: 6.24 ms, total: 1.09 s\n",
            "Wall time: 1.41 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For test dataset we call only transform method:"
      ],
      "metadata": {
        "id": "EhNEP7BSTI33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "test_data = vectorizer.transform(test_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIO_XlNoSXIQ",
        "outputId": "f71d69f9-3b94-4575-efed-a268ae69ad1c"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 409 ms, sys: 1.03 ms, total: 410 ms\n",
            "Wall time: 478 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The list of words in vocabulary:"
      ],
      "metadata": {
        "id": "djJ_0fOP5OxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()[1000:1020]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy7ARje8TgUt",
        "outputId": "81f316fc-717d-4c2e-d6c2-73ec71017bd9"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['advertised', 'advertisement', 'advertisements', 'advertiser',\n",
              "       'advertising', 'advertisment', 'advice', 'advil', 'advisable',\n",
              "       'advise', 'advised', 'adviser', 'advisers', 'advises', 'advising',\n",
              "       'advisor', 'advisors', 'advocate', 'advocated', 'advocates'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weights of pre-trained model:"
      ],
      "metadata": {
        "id": "8-MkIwXE5VDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing and training Logistic regression model:"
      ],
      "metadata": {
        "id": "L4ufpW0GRcex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0)\n",
        "clf.fit(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCrgKDzDYoZ-",
        "outputId": "8fe88e1d-1b2b-4797-d3d9-bd4c3356f634"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.coef_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLeshXsl5ND0",
        "outputId": "56d1697d-0bab-4605-990e-b84886fd9b34"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 34471)"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data = clf.predict(test_data)"
      ],
      "metadata": {
        "id": "boxuHZdjZFaH"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_labels, pred_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOiR8-2U4A24",
        "outputId": "30eaf330-e328-4b20-f203-9eb1d63bb27d"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82       301\n",
            "           1       0.82      0.82      0.82       299\n",
            "\n",
            "    accuracy                           0.82       600\n",
            "   macro avg       0.82      0.82      0.82       600\n",
            "weighted avg       0.82      0.82      0.82       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic reression with bag of words:"
      ],
      "metadata": {
        "id": "T5xHs2Vv4Zdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "train_data = vectorizer.fit_transform(train_texts)\n",
        "test_data = vectorizer.transform(test_texts)\n",
        "\n",
        "clf = LogisticRegression(random_state=0)\n",
        "clf.fit(train_data, train_labels)\n",
        "pred_data = clf.predict(test_data)\n",
        "print(classification_report(test_labels, pred_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G6VhcdL4h14",
        "outputId": "2d759f5c-fe61-43c8-e09a-8901b5081aa4"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83       301\n",
            "           1       0.84      0.81      0.82       299\n",
            "\n",
            "    accuracy                           0.83       600\n",
            "   macro avg       0.83      0.83      0.83       600\n",
            "weighted avg       0.83      0.83      0.83       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks:\n",
        "1. Get the most important feature for pre-trained Logistic regression model\n",
        "2. Add lemmatisation or stemming as text preprocessing\n",
        "3. Remove stopwords from CountVectorizer or TfidfVectorizer with stop_words parameter\n",
        "4. Add bigrams and threegrams to CountVectorizer or TfidfVectorizer with ngram_range parameter"
      ],
      "metadata": {
        "id": "GCBeaLxq41SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "tRHlMDcLY9ch"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(abs(clf.coef_))"
      ],
      "metadata": {
        "id": "trXgd-o05t30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5cd6dea-e1a6-4ebc-91c1-507aa9e0239b"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2579"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()[2529]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1Q93rJ67ZBZH",
        "outputId": "4a449833-cf19-41e4-ecae-a50ca4944256"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'babysit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()[1000:1020]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJIUu96EbGQF",
        "outputId": "847c534f-71dd-4b4e-cf01-b380dc6e30a4"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['advertised', 'advertisement', 'advertisements', 'advertiser',\n",
              "       'advertising', 'advertisment', 'advice', 'advil', 'advisable',\n",
              "       'advise', 'advised', 'adviser', 'advisers', 'advises', 'advising',\n",
              "       'advisor', 'advisors', 'advocate', 'advocated', 'advocates'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz2A2QaBZuoc",
        "outputId": "97613ee3-e58b-4b58-ee44-accfcbba77cd"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/55.5 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=a687b0e94f64884ac7e8412050cbb7a09a57602da81a3b5d8af1ff6b3702424e\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "morph = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "RePOPEDoZw_2"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR3UuCS4cpPH",
        "outputId": "80aa0c06-e0ea-4f20-c627-1921344dc82a"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.stem.PorterStemmer()\n",
        "\n",
        "def my_tokenize(text):\n",
        "  words = nltk.word_tokenize(text)\n",
        "  res_words = [stemmer.stem(word) for word in words]\n",
        "  return ' '.join(res_words)"
      ],
      "metadata": {
        "id": "UxBZxKgxZ1iD"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tokenize(\"writing text\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aa7OoYgeaCTu",
        "outputId": "8b48831f-d21c-4a67-dfb3-cbd5d46f2627"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'write text'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(analyzer=my_tokenize)\n",
        "train_data = vectorizer.fit_transform(train_texts)\n",
        "test_data = vectorizer.transform(test_texts)\n",
        "\n",
        "clf = LogisticRegression(random_state=0)\n",
        "clf.fit(train_data, train_labels)\n",
        "pred_data = clf.predict(test_data)\n",
        "print(classification_report(test_labels, pred_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Z7Td2GZbLa",
        "outputId": "973db73b-204d-4583-fbf3-d6fed5ec6ba2"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.58      0.61       301\n",
            "           1       0.61      0.67      0.64       299\n",
            "\n",
            "    accuracy                           0.62       600\n",
            "   macro avg       0.62      0.62      0.62       600\n",
            "weighted avg       0.62      0.62      0.62       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}